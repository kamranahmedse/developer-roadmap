# Gradient Boosting Machines

Gradient Boosting Machines (GBMs) are a type of ensemble learning algorithm that combines the predictions from multiple weaker models, typically decision trees, to create a stronger, more accurate model. The algorithm works iteratively, with each new tree trained to correct the errors made by the previous trees. This correction is achieved by focusing on the instances that were poorly predicted by the existing ensemble, effectively "boosting" the performance on those difficult cases. The final prediction is made by aggregating the predictions of all the trees in the ensemble.

Visit the following resources to learn more:

- [@article@Gradient Boosting Classifier | scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)
- [@article@A Guide to The Gradient Boosting Algorithm](https://www.datacamp.com/tutorial/guide-to-the-gradient-boosting-algorithm)
- [@video@Gradient Boosting in Scikit-Learn: Hands-On Tutorial](https://www.youtube.com/watch?v=E2mCaIZNE2g)