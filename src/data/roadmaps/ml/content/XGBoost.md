# XGBoost: 

XGBoost is a popular gradient-boosting library for GPU training, distributed computing, and parallelization. It’s precise, it adapts well to all types of data and problems, it has excellent documentation, and overall it’s very easy to use. At the moment it’s the de facto standard algorithm for getting accurate results from predictive modeling with machine learning. It’s the fastest gradient-boosting library for R, Python, and C++ with very high accuracy.

- [XGBoost documentation](https://xgboost.readthedocs.io/)
- [XGBoost GitHub repository](https://github.com/dmlc/xgboost)
- [XGBoost on Python package](https://xgboost.readthedocs.io/en/latest/python/python_api.html)
- [XGBoost on R package](https://xgboost.readthedocs.io/en/latest/R-package/index.html)
- [XGBoost by datacamp](https://www.datacamp.com/community/tutorials/xgboost-in-python)
- [Intro to XGBoost by datacamp](https://youtu.be/gUJVmds9DsI)
- [XGBoost algorithm](https://youtu.be/PxgVFp5a0E4)