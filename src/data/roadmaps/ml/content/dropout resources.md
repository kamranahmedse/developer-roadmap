# Regularisation-Dropout Resources

Regularization and Dropout are two commonly used techniques in deep learning to prevent overfitting of the model to the training data. Here are some resources to learn more about them:

"Regularization" section of the Deep Learning book by Ian Goodfellow, Yoshua Bengio, and Aaron Courville: This section of the book provides a detailed explanation of regularization techniques, including L1 and L2 regularization, dropout, and data augmentation.

"Dropout: A Simple Way to Prevent Neural Networks from Overfitting" by Nitish Srivastava et al.: This seminal paper introduced the dropout technique and provides an in-depth explanation of how it works and its benefits.

Visit the following resources to learn more:

- [Regularisation-Dropout Resources](https://www.kdnuggets.com/2018/01/regularization-machine-learning.html)
- [definition of Regularisation-Dropout Resources](https://c3iot.ai/glossary/machine-learning/regularization/)
- [Regularisation-Dropout Resources.video](https://edu.machinelearningplus.com/courses/Linear-Regression-and-Regularisation-61976a530cf2030e987c0dd5)
- [coursera for Regularisation-Dropout Resources](https://gb.coursera.org/lecture/advanced-machine-learning-signal-processing/regularization-Ezk3r)

