# Learning-Rate

Learning rate is a hyperparameter that plays a critical role in the training of machine learning models. It determines the size of the steps taken during gradient descent, which is the optimization algorithm used to update the parameters of the model during training. The learning rate can have a significant impact on the training process and the performance of the model. If the learning rate is too high, the optimization process may oscillate around the optimal solution or even diverge. If the learning rate is too low, the optimization process may take a long time to converge to the optimal solution. Thus, finding an appropriate learning rate is crucial for achieving good performance in machine learning tasks. Various techniques, such as learning rate schedules, adaptive learning rates, and cyclical learning rates, can be used to tune the learning rate during training .

- [Learning Rate](https://machinelearningmastery.com/learning-rate-for-deep-learning-neural-networks/)
- [How to use Learning Rate](https://youtu.be/G-kz8NIPkP4)
- [Annealing Learning Rate](https://cs231n.github.io/neural-networks-3/#anneal)
- [Course](https://www.coursera.org/learn/deep-neural-network?specialization=deep-learning)
