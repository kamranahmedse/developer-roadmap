# Gradient Descent 

Gradient Descent is an optimization algorithm commonly used in machine learning and deep learning to minimize the cost function of a model. The cost function measures how well the model is performing in terms of its ability to make accurate predictions. In Gradient Descent, the goal is to find the set of parameters that minimizes the cost function. The algorithm achieves this by iteratively updating the parameters in the direction of steepest descent of the cost function, which is the negative gradient. In other words, it adjusts the parameters in small steps that reduce the error between the predicted and actual values

-  [What is Gradient Descent ? ](https://builtin.com/data-science/gradient-descent)
- [How Does Gradient descent work and its type](https://www.ibm.com/in-en/topics/gradient-descent)
- [Gradient descent simple explanation](https://youtu.be/gzrQvzYEvYc)
-  [Gradient descent Great learning](https://www.mygreatlearning.com/academy/learn-for-free/courses/stochastic-gradient-descent?utm_source=share_with_friends&gl_source=share_with_friends)
