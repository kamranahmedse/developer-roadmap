# Capabilities / Context Length

A key aspect of the OpenAI models is their context length, which refers to the amount of input text the model can process at once. Earlier models like GPT-3 had a context length of up to 4,096 tokens (words or word pieces), while more recent models like GPT-4 can handle significantly larger context lengths, some supporting up to 32,768 tokens. This extended context length enables the models to handle more complex tasks, such as maintaining long conversations or processing lengthy documents, which enhances their utility in real-world applications like legal document analysis or code generation.

Visit the following resources to learn more:

- [@official@Managing Context](https://platform.openai.com/docs/guides/conversation-state?api-mode=responses#managing-context-for-text-generation)
- [@official@Capabilities](https://platform.openai.com/docs/guides/text-generation)