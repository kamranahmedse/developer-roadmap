# Airflow

Airflow is a platform used to programmatically author, schedule, and monitor workflows. It allows you to define workflows as Directed Acyclic Graphs (DAGs) of tasks, where each task represents a unit of work. Airflow then executes these tasks in the specified order, handling dependencies, retries, and logging along the way.

Visit the following resources to learn more:

- [@official@Airflow](https://airflow.apache.org/)
- [@official@Airflow Docs](https://airflow.apache.org/docs)
- [@opensource@airflow](https://github.com/apache/airflow)
- [@article@Building Pipelines In Apache Airflow â€“ For Beginners](https://towardsdatascience.com/building-pipelines-in-apache-airflow-for-beginners-58f87a1512d5/?utm_source=roadmap&utm_medium=Referral&utm_campaign=TDS+roadmap+integration)
- [@video@What is Apache Airflow? For beginners](https://www.youtube.com/watch?v=CGxxVj13sOs)
- [@video@Apache Airflow Tutorial for Data Engineers](https://www.youtube.com/watch?v=y5rYZLBZ_Fw)
- [@feed@Explore top posts about Apache Airflow](https://app.daily.dev/tags/apache-airflow?ref=roadmapsh)