# Model Evaluation

Model evaluation is the process of assessing the performance of a machine learning model using various metrics and techniques. It helps determine how well the model generalizes to unseen data and whether it meets the desired performance criteria. This involves using different evaluation metrics depending on the type of problem (e.g., accuracy, precision, recall, F1-score for classification; RMSE, MAE for regression) and employing techniques like cross-validation to obtain a reliable estimate of the model's performance.

Visit the following resources to learn more:

- [@article@What is Model Evaluation](https://domino.ai/data-science-dictionary/model-evaluation)
- [@article@Model Evaluation Metrics](https://www.markovml.com/blog/model-evaluation-metrics)
- [@article@How to Evaluate the Performance of Your ML/ AI Models](https://towardsdatascience.com/how-to-evaluate-the-performance-of-your-ml-ai-models-ba1debc6f2fa/?utm_source=roadmap&utm_medium=Referral&utm_campaign=TDS+roadmap+integration)
- [@video@How to evaluate ML models | Evaluation metrics for machine learning](https://www.youtube.com/watch?v=LbX4X71-TFI)