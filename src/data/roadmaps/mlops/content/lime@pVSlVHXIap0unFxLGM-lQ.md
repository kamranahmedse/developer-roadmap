# LIME

LIME (Local Interpretable Model-agnostic Explanations) is a technique used to understand the predictions of machine learning models. It works by approximating the model locally with a simpler, interpretable model, such as a linear model. This simpler model is trained on perturbations of the data point being explained, allowing users to understand which features are most important for that specific prediction.

Visit the following resources to learn more:

- [@opensource@lime](https://github.com/marcotcr/lime)
- [@article@Explainable AI - Understanding and Trusting Machine Learning Models](https://www.datacamp.com/tutorial/explainable-ai-understanding-and-trusting-machine-learning-models)
- [@video@Explainable AI explained! | #3 LIME](https://www.youtube.com/watch?v=d6j6bofhj2M)